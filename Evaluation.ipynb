{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "\n",
    "import pymysql\n",
    "\n",
    "import multiprocessing\n",
    "\n",
    "from multiprocessing import Process, Queue\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from bert.tokenization.bert_tokenization import FullTokenizer\n",
    "\n",
    "from utils.utils import calcAccTextModel, checkDataframe, convertRowToDictionary, loadMeanFromFile\n",
    "\n",
    "from utils.datagenUtils.DataSeqImageTitle import DataSequenceImageTitle\n",
    "from utils.datagenUtils.DataSeqTitleMeta import DataSequenceTitleMeta \n",
    "from utils.datagenUtils.DataSeqMetaModel import DataSequenceMetaModel\n",
    "from utils.datagenUtils.DataSequenceTitleCommentsVisual import DataSequenceTitleCommentsVisual\n",
    "from utils.datagenUtils.DataSeqFourModels import DataSequenceFourModels\n",
    "\n",
    "from utils.textUtils.textpreprocessing import FakeDetectionDataTrainVal, FakeDetectionDataTest\n",
    "from utils.textUtils.commentsProcessing import FakeDetectionDataCommentsTest, FakeDetectionDataCommentsTrainVal\n",
    "\n",
    "\n",
    "from best_models.final_models import create_text_model, create_image_inceptionv3_model, create_model_meta, buildConcatModelTitleImage, buildConcatModelTitleCommentsVisual, buildConcatModelTitleCommentsMetaVisual, buildConcatModelTitleMeta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Verbose settings:\n",
    "verbose = False\n",
    "TF_VERBOSE = 1 # 1 = Progress bar 2 = one line per epoch only!\n",
    "TF_DETERMINISTIC_OPS = 1 # Makes everything also on GPU deterministic\n",
    "\n",
    "# Classes:\n",
    "NUM_CLASS = 2  # FAKE | NO FAKE\n",
    "\n",
    "# Hyperparameters\n",
    "GLOBAL_BATCH_SIZE = 32\n",
    "EPOCHS = 10\n",
    "# Bert Parameters\n",
    "MAX_SEQUENCE_LENGTH = 128 # from model definition!\n",
    "\n",
    "# Image Model  Parameters\n",
    "IMG_WIDTH = 768\n",
    "IMG_HEIGHT = 768\n",
    "IMG_DEPTH = 3\n",
    "IMG_SIZES = (IMG_WIDTH, IMG_HEIGHT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = pathToRootModelDir = '/home/armin/repos/fid-evaluation'\n",
    "pathToRootModelDir = os.path.join(root, 'best_models')\n",
    "\n",
    "pathToBertModelTitle = os.path.join(pathToRootModelDir, '01_mono_modal', 'title', 'weights-improvement-02-0.88.hdf5')\n",
    "pathToBertModelComments = os.path.join(pathToRootModelDir, '01_mono_modal', 'comments', 'weights-improvement-03-0.87.hdf5')\n",
    "pathToImageModel = os.path.join(pathToRootModelDir, '01_mono_modal', 'visual', 'weights-improvement-02-0.81.hdf5')\n",
    "pathToMetaModel = os.path.join(pathToRootModelDir, '01_mono_modal', 'meta', 'weights-improvement-100-0.62.hdf5')\n",
    "\n",
    "pathToTitleImageModel = os.path.join(pathToRootModelDir, '02_dual_modal', 'title_visual', 'weights-improvement-02-0.91.hdf5')\n",
    "\n",
    "pathToTitleMetaModel = os.path.join(pathToRootModelDir, '02_dual_modal', 'title_meta', 'weights-improvement-09-0.88.hdf5')\n",
    "\n",
    "pathToTitleCommentsImage = os.path.join(pathToRootModelDir, '03_triple_modal', 'titleCommentsVisual', 'weights-improvement-06-0.95.hdf5')\n",
    "\n",
    "pathToTitleCommentsImageMeta = os.path.join(pathToRootModelDir, '04_four_modal', 'weights-improvement-12-0.95.hdf5')\n",
    "                                            \n",
    "pathToImagesTrain = '/home/armin/repos/FKD-Dataset/006_images_resized_2/train/' \n",
    "pathToCSVWithFileNamesAndLabelsTrain = '/home/armin/repos/FKD-Dataset/008_text_image_meta_label/train_text_image_meta_label.csv'\n",
    "\n",
    "pathToImagesVal = '/home/armin/repos/FKD-Dataset/006_images_resized_2/val/' \n",
    "pathToCSVWithFileNamesAndLabelsVal = '/home/armin/repos/FKD-Dataset/008_text_image_meta_label/val_text_image_meta_label.csv'\n",
    "\n",
    "pathToImagesTest = '/home/armin/repos/FKD-Dataset/006_images_resized_2/test/' \n",
    "pathToCSVWithFileNamesAndLabelsTest = '/home/armin/repos/FKD-Dataset/008_text_image_meta_label/test_text_image_meta_label.csv'\n",
    "\n",
    "\n",
    "pathToMeans = '/home/armin/repos/FKD-Dataset/010_configs/means_resized_768.txt'\n",
    "\n",
    "\n",
    "bert_model_dir = os.path.join(root, 'multi_cased_L-12_H-768_A-12')\n",
    "vocab_file = os.path.join(bert_model_dir, \"vocab.txt\")\n",
    "bert_ckpt_file = os.path.join(bert_model_dir, \"bert_model.ckpt\")\n",
    "bert_config_file = os.path.join(bert_model_dir, \"bert_config.json\")\n",
    "\n",
    "\n",
    "pathToEvalValCSV = os.path.join(root, 'evaluation_best_models_val.csv')\n",
    "pathToEvalTestCSV = os.path.join(root, 'evaluation_best_models_test.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Needed to remove 14 elements to make it matching from dataframe\n",
      "Warning: Needed to remove 28 elements to make it matching from dataframe\n",
      "Warning: Needed to remove 10 elements to make it matching from dataframe\n"
     ]
    }
   ],
   "source": [
    "df_train_ = pd.read_csv(pathToCSVWithFileNamesAndLabelsTrain, header=0, sep='\\t')\n",
    "df_test_ = pd.read_csv(pathToCSVWithFileNamesAndLabelsTest, header=0, sep='\\t')\n",
    "df_val_ = pd.read_csv(pathToCSVWithFileNamesAndLabelsVal, header=0, sep='\\t')\n",
    "\n",
    "df_train_['2_way_label'] = df_train_['2_way_label'].apply(lambda x: np.array(x))\n",
    "df_test_['2_way_label'] = df_test_['2_way_label'].apply(lambda x: np.array(x))\n",
    "df_val_['2_way_label'] = df_val_['2_way_label'].apply(lambda x: np.array(x))\n",
    "\n",
    "df_train = df_train_\n",
    "df_test = df_test_\n",
    "df_val = df_val_\n",
    "\n",
    "# df_train = df_train[:500]\n",
    "# df_test = df_test[:500]\n",
    "# df_val = df_val[:500]\n",
    "\n",
    "df_train = checkDataframe(df_train, GLOBAL_BATCH_SIZE)\n",
    "df_val = checkDataframe(df_val, GLOBAL_BATCH_SIZE)\n",
    "df_test = checkDataframe(df_test, GLOBAL_BATCH_SIZE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "560608it [01:53, 4927.28it/s]\n",
      "58944it [00:11, 5036.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max seq_len 687\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "58944it [00:11, 5028.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max seq_len 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "560608it [32:28, 287.77it/s]\n",
      "58944it [03:33, 276.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max seq_len 55475\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "58944it [03:31, 278.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max seq_len 39424\n"
     ]
    }
   ],
   "source": [
    "tokenizer = FullTokenizer(vocab_file=vocab_file)\n",
    "\n",
    "all_title_data = FakeDetectionDataTrainVal(df_train, df_val, tokenizer, [0,1], MAX_SEQUENCE_LENGTH)\n",
    "\n",
    "all_title_test = FakeDetectionDataTest(df_test, tokenizer, [0,1], MAX_SEQUENCE_LENGTH)\n",
    "\n",
    "\n",
    "comments_data_train = FakeDetectionDataCommentsTrainVal(df_train, df_val, tokenizer, [0,1], MAX_SEQUENCE_LENGTH)\n",
    "\n",
    "comments_data_test = FakeDetectionDataCommentsTest(df_test, tokenizer, [0,1], MAX_SEQUENCE_LENGTH)\n",
    "\n",
    "train_title_x = all_title_data.train_x\n",
    "train_title_val_x = all_title_data.val_x\n",
    "test_title_x = all_title_test.test_x\n",
    "\n",
    "comments_train_x = comments_data_train.train_x\n",
    "comments_val_x = comments_data_train.val_x\n",
    "comments_test_x = comments_data_test.test_x\n",
    "\n",
    "train_seq_meta = DataSequenceMetaModel(df_train, GLOBAL_BATCH_SIZE)\n",
    "test_seq_meta = DataSequenceMetaModel(df_test, GLOBAL_BATCH_SIZE)\n",
    "val_seq_meta = DataSequenceMetaModel(df_val, GLOBAL_BATCH_SIZE)\n",
    "\n",
    "# dual modal\n",
    "meansOfDataset = loadMeanFromFile(pathToMeans, verbose)\n",
    "\n",
    "test_seq_dual = DataSequenceImageTitle(df_test, pathToImagesTest,  test_title_x, GLOBAL_BATCH_SIZE, IMG_SIZES, meansOfDataset)\n",
    "\n",
    "val_seq_dual = DataSequenceImageTitle(df_val, pathToImagesVal,  train_title_val_x, GLOBAL_BATCH_SIZE, IMG_SIZES, meansOfDataset)\n",
    "\n",
    "val_seq_dual_title_meta = DataSequenceTitleMeta(df_val, train_title_val_x, GLOBAL_BATCH_SIZE)\n",
    "\n",
    "test_seq_dual_title_meta = DataSequenceTitleMeta(df_test, test_title_x, GLOBAL_BATCH_SIZE)\n",
    "\n",
    "#triple modal\n",
    "\n",
    "test_seq_triple = DataSequenceTitleCommentsVisual(df_test, pathToImagesTest, test_title_x, comments_test_x, GLOBAL_BATCH_SIZE, IMG_SIZES, meansOfDataset)\n",
    "\n",
    "val_seq_triple = DataSequenceTitleCommentsVisual(df_val,pathToImagesVal, train_title_val_x, comments_val_x, GLOBAL_BATCH_SIZE, IMG_SIZES, meansOfDataset)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "meansOfDataset = loadMeanFromFile(pathToMeans, verbose)\n",
    "\n",
    "train_seq = DataSequenceFourModels(df_train, pathToImagesTrain, train_title_x, comments_train_x, GLOBAL_BATCH_SIZE, IMG_SIZES, meansOfDataset)\n",
    "\n",
    "test_seq = DataSequenceFourModels(df_test, pathToImagesTest, test_title_x, comments_test_x, GLOBAL_BATCH_SIZE, IMG_SIZES, meansOfDataset)\n",
    "\n",
    "val_seq = DataSequenceFourModels(df_val,pathToImagesVal, train_title_val_x, comments_val_x, GLOBAL_BATCH_SIZE, IMG_SIZES, meansOfDataset)\n",
    "\n",
    "STEP_SIZE_TRAIN = len(df_train) // GLOBAL_BATCH_SIZE\n",
    "STEP_SIZE_TEST = len(df_test) // GLOBAL_BATCH_SIZE\n",
    "STEP_SIZE_VAL = len(df_val) // GLOBAL_BATCH_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare copy of DF\n",
    "\n",
    "df_eval_val = df_val.copy()\n",
    "df_eval_test = df_test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluateTitleVal():\n",
    "    mirrored_strategy = tf.distribute.MirroredStrategy()\n",
    "    with mirrored_strategy.scope():\n",
    "        title_model, custom_layer = create_text_model(MAX_SEQUENCE_LENGTH, bert_ckpt_file, bert_config_file, NUM_CLASS, False, True, pathToBertModelTitle, False)\n",
    "\n",
    "        preds =  title_model.predict(all_title_data.train_x, use_multiprocessing=False, batch_size = GLOBAL_BATCH_SIZE, verbose=1) \n",
    "        test_max = np.argmax(preds, axis=1)\n",
    "\n",
    "        try:\n",
    "            df_eval_val.insert(loc=df_eval_val.shape[1], column='eval_title_pred_label_val', value=np.nan)\n",
    "        except ValueError:\n",
    "            print('Found columns, ignoring inserting')\n",
    "\n",
    "        for index, row in enumerate(df_eval_val.itertuples(), 1):\n",
    "            rowFine = convertRowToDictionary(row, df_eval_val.columns, True)\n",
    "            df_eval_val.at[row[0], 'eval_title_pred_label_val'] = int(test_max[index-1])\n",
    "        Q.put(df_eval_val)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluateTitleTest():\n",
    "    title_model, custom_layer = create_text_model(MAX_SEQUENCE_LENGTH, bert_ckpt_file, bert_config_file, NUM_CLASS, False, True, pathToBertModelTitle, False)\n",
    "    \n",
    "    preds =  title_model.predict(all_title_test.test_x, use_multiprocessing=False, batch_size = GLOBAL_BATCH_SIZE, verbose=1) \n",
    "    test_max = np.argmax(preds, axis=1)\n",
    "    \n",
    "    try:\n",
    "        df_eval_test.insert(loc=df_eval_test.shape[1], column='eval_title_pred_label_test', value=np.nan)\n",
    "    except ValueError:\n",
    "        print('Found columns, ignoring inserting')\n",
    "    \n",
    "    for index, row in enumerate(df_eval_test.itertuples(), 1):\n",
    "        rowFine = convertRowToDictionary(row, df_eval_test.columns, True)\n",
    "        df_eval_test.at[row[0], 'eval_title_pred_label_test'] = int(test_max[index-1])\n",
    "    Q.put(df_eval_test)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3')\n",
      "bert shape (None, 128, 768)\n",
      "17519/17519 [==============================] - 1214s 69ms/step\n",
      "bert shape (None, 128, 768)\n",
      "1842/1842 [==============================] - 405s 220ms/step\n"
     ]
    }
   ],
   "source": [
    "Q = Queue()\n",
    "process_eval = Process(target=evaluateTitleVal, args=())\n",
    "process_eval.start()\n",
    "df_eval_val = Q.get()\n",
    "process_eval.join()\n",
    "\n",
    "Q = Queue()\n",
    "process_eval = Process(target=evaluateTitleTest, args=())\n",
    "process_eval.start()\n",
    "df_eval_test = Q.get()\n",
    "process_eval.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluateCommentsVal():\n",
    "    mirrored_strategy = tf.distribute.MirroredStrategy()\n",
    "    with mirrored_strategy.scope():\n",
    "        comments_model, comments_modal_custom_layer = create_text_model(max_seq_len=MAX_SEQUENCE_LENGTH, bert_ckpt_file=bert_ckpt_file, bert_config_file= bert_config_file,NUM_CLASS=NUM_CLASS, overwriteLayerAndEmbeddingSize=False, isPreTrained=True,  pathToBertModelWeights=pathToBertModelComments, isTrainable=False) \n",
    "\n",
    "        preds =  comments_model.predict(comments_val_x, use_multiprocessing=False, batch_size = GLOBAL_BATCH_SIZE, verbose=1) \n",
    "        test_max = np.argmax(preds, axis=1)\n",
    "\n",
    "        try:\n",
    "            df_eval_val.insert(loc=df_eval_val.shape[1], column='eval_comments_pred_label_val', value=np.nan)\n",
    "        except ValueError:\n",
    "            print('Found columns, ignoring inserting')\n",
    "\n",
    "        for index, row in enumerate(df_eval_val.itertuples(), 1):\n",
    "            rowFine = convertRowToDictionary(row, df_eval_val.columns, True)\n",
    "            df_eval_val.at[row[0], 'eval_comments_pred_label_val'] = int(test_max[index-1])\n",
    "        Q.put(df_eval_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluateCommentsTest():\n",
    "    mirrored_strategy = tf.distribute.MirroredStrategy()\n",
    "    with mirrored_strategy.scope():\n",
    "        comments_model, comments_modal_custom_layer = create_text_model(max_seq_len=MAX_SEQUENCE_LENGTH, bert_ckpt_file=bert_ckpt_file, bert_config_file= bert_config_file,NUM_CLASS=NUM_CLASS, overwriteLayerAndEmbeddingSize=False, isPreTrained=True,  pathToBertModelWeights=pathToBertModelComments, isTrainable=False) \n",
    "\n",
    "        preds =  comments_model.predict(comments_test_x, use_multiprocessing=False, batch_size = GLOBAL_BATCH_SIZE, verbose=1) \n",
    "        test_max = np.argmax(preds, axis=1)\n",
    "\n",
    "        try:\n",
    "            df_eval_test.insert(loc=df_eval_test.shape[1], column='eval_comments_pred_label_test', value=np.nan)\n",
    "        except ValueError:\n",
    "            print('Found columns, ignoring inserting')\n",
    "\n",
    "        for index, row in enumerate(df_eval_test.itertuples(), 1):\n",
    "            rowFine = convertRowToDictionary(row, df_eval_test.columns, True)\n",
    "            df_eval_test.at[row[0], 'eval_comments_pred_label_test'] = int(test_max[index-1])\n",
    "        Q.put(df_eval_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3')\n",
      "bert shape (None, 128, 768)\n",
      "1842/1842 [==============================] - 126s 69ms/step\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3')\n",
      "bert shape (None, 128, 768)\n",
      "1842/1842 [==============================] - 128s 69ms/step\n"
     ]
    }
   ],
   "source": [
    "Q = Queue()\n",
    "process_eval = Process(target=evaluateCommentsVal, args=())\n",
    "process_eval.start()\n",
    "df_eval_val = Q.get()\n",
    "process_eval.join()\n",
    "\n",
    "Q = Queue()\n",
    "process_eval = Process(target=evaluateCommentsTest, args=())\n",
    "process_eval.start()\n",
    "df_eval_test = Q.get()\n",
    "process_eval.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluateVisualVal():\n",
    "    mirrored_strategy = tf.distribute.MirroredStrategy()\n",
    "    with mirrored_strategy.scope():\n",
    "        inception_model, model_image_custom_layer = create_image_inceptionv3_model(NUM_CLASS=NUM_CLASS,isPreTrained=True,pathToInceptionV3ModelWeights=pathToImageModel, isTrainable=False)\n",
    "\n",
    "        preds =  inception_model.predict(val_seq, use_multiprocessing=False, batch_size = GLOBAL_BATCH_SIZE, verbose=1) \n",
    "        test_max = np.argmax(preds, axis=1)\n",
    "\n",
    "        try:\n",
    "            df_eval_val.insert(loc=df_eval_val.shape[1], column='eval_visual_pred_label_val', value=np.nan)\n",
    "        except ValueError:\n",
    "            print('Found columns, ignoring inserting')\n",
    "\n",
    "        for index, row in enumerate(df_eval_val.itertuples(), 1):\n",
    "            rowFine = convertRowToDictionary(row, df_eval_val.columns, True)\n",
    "            df_eval_val.at[row[0], 'eval_visual_pred_label_val'] = int(test_max[index-1])\n",
    "        Q.put(df_eval_val)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluateVisualTest():\n",
    "    mirrored_strategy = tf.distribute.MirroredStrategy()\n",
    "    with mirrored_strategy.scope():\n",
    "        inception_model, model_image_custom_layer = create_image_inceptionv3_model(NUM_CLASS=NUM_CLASS,isPreTrained=True,pathToInceptionV3ModelWeights=pathToImageModel, isTrainable=False)\n",
    "\n",
    "        preds =  inception_model.predict(val_seq, use_multiprocessing=False, batch_size = GLOBAL_BATCH_SIZE, verbose=1) \n",
    "        test_max = np.argmax(preds, axis=1)\n",
    "\n",
    "        try:\n",
    "            df_eval_test.insert(loc=df_eval_test.shape[1], column='eval_visual_pred_label_test', value=np.nan)\n",
    "        except ValueError:\n",
    "            print('Found columns, ignoring inserting')\n",
    "\n",
    "        for index, row in enumerate(df_eval_test.itertuples(), 1):\n",
    "            rowFine = convertRowToDictionary(row, df_eval_test.columns, True)\n",
    "            df_eval_test.at[row[0], 'eval_visual_pred_label_test'] = int(test_max[index-1])\n",
    "        Q.put(df_eval_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3')\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "1842/1842 [==============================] - 1372s 745ms/step\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3')\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "1842/1842 [==============================] - 1367s 742ms/step\n"
     ]
    }
   ],
   "source": [
    "Q = Queue()\n",
    "process_eval = Process(target=evaluateVisualVal, args=())\n",
    "process_eval.start()\n",
    "df_eval_val = Q.get()\n",
    "process_eval.join()\n",
    "\n",
    "Q = Queue()\n",
    "process_eval = Process(target=evaluateVisualTest, args=())\n",
    "process_eval.start()\n",
    "df_eval_test = Q.get()\n",
    "process_eval.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluateMetaFeatureVal():\n",
    "    mirrored_strategy = tf.distribute.MirroredStrategy()\n",
    "    with mirrored_strategy.scope():\n",
    "        meta_model, model_meta_custom_layer = create_model_meta(NUM_CLASS, 2, True, pathToMetaModel, isTrainable=False)\n",
    "\n",
    "        preds =  meta_model.predict(val_seq_meta, use_multiprocessing=False, batch_size = GLOBAL_BATCH_SIZE, verbose=1) \n",
    "        test_max = np.argmax(preds, axis=1)\n",
    "\n",
    "        try:\n",
    "            df_eval_val.insert(loc=df_eval_val.shape[1], column='eval_meta_pred_label_val', value=np.nan)\n",
    "        except ValueError:\n",
    "            print('Found columns, ignoring inserting')\n",
    "\n",
    "        for index, row in enumerate(df_eval_val.itertuples(), 1):\n",
    "            rowFine = convertRowToDictionary(row, df_eval_val.columns, True)\n",
    "            df_eval_val.at[row[0], 'eval_meta_pred_label_val'] = int(test_max[index-1])\n",
    "        Q.put(df_eval_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluateMetaFeatureTest():\n",
    "    mirrored_strategy = tf.distribute.MirroredStrategy()\n",
    "    with mirrored_strategy.scope():\n",
    "        meta_model, model_meta_custom_layer = create_model_meta(NUM_CLASS, 2, True, pathToMetaModel, isTrainable=False)\n",
    "\n",
    "        preds =  meta_model.predict(test_seq_meta, use_multiprocessing=False, batch_size = GLOBAL_BATCH_SIZE, verbose=1) \n",
    "        test_max = np.argmax(preds, axis=1)\n",
    "\n",
    "        try:\n",
    "            df_eval_test.insert(loc=df_eval_test.shape[1], column='eval_meta_pred_label_test', value=np.nan)\n",
    "        except ValueError:\n",
    "            print('Found columns, ignoring inserting')\n",
    "\n",
    "        for index, row in enumerate(df_eval_test.itertuples(), 1):\n",
    "            rowFine = convertRowToDictionary(row, df_eval_test.columns, True)\n",
    "            df_eval_test.at[row[0], 'eval_meta_pred_label_test'] = int(test_max[index-1])\n",
    "        Q.put(df_eval_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3')\n",
      "1842/1842 [==============================] - 9s 5ms/step\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3')\n",
      "1842/1842 [==============================] - 8s 5ms/step\n"
     ]
    }
   ],
   "source": [
    "Q = Queue()\n",
    "process_eval = Process(target=evaluateMetaFeatureVal, args=())\n",
    "process_eval.start()\n",
    "df_eval_val = Q.get()\n",
    "process_eval.join()\n",
    "\n",
    "Q = Queue()\n",
    "process_eval = Process(target=evaluateMetaFeatureTest, args=())\n",
    "process_eval.start()\n",
    "df_eval_test = Q.get()\n",
    "process_eval.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluateTitleMetaVal():\n",
    "    mirrored_strategy = tf.distribute.MirroredStrategy()\n",
    "    with mirrored_strategy.scope():\n",
    "        \n",
    "        \n",
    "        title_model, custom_layer = create_text_model(MAX_SEQUENCE_LENGTH, bert_ckpt_file, bert_config_file, NUM_CLASS, False, True, pathToBertModelTitle, False)\n",
    "        meta_model, model_meta_custom_layer = create_model_meta(NUM_CLASS, 2, True, pathToMetaModel, isTrainable=False)\n",
    "        \n",
    "        titleMetaModel, titleMetaModel_custom_layer = buildConcatModelTitleMeta(title_model, meta_model, 2, True, pathToTitleMetaModel, False)\n",
    "\n",
    "        preds =  titleMetaModel.predict(val_seq_dual_title_meta, use_multiprocessing=False, batch_size = GLOBAL_BATCH_SIZE, verbose=1) \n",
    "        test_max = np.argmax(preds, axis=1)\n",
    "\n",
    "        try:\n",
    "            df_eval_val.insert(loc=df_eval_val.shape[1], column='eval_dual_title_meta_pred_label_val', value=np.nan)\n",
    "        except ValueError:\n",
    "            print('Found columns, ignoring inserting')\n",
    "\n",
    "        for index, row in enumerate(df_eval_val.itertuples(), 1):\n",
    "            rowFine = convertRowToDictionary(row, df_eval_val.columns, True)\n",
    "            df_eval_val.at[row[0], 'eval_dual_title_meta_pred_label_val'] = int(test_max[index-1])\n",
    "        Q.put(df_eval_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluateTitleMetaTest():\n",
    "    mirrored_strategy = tf.distribute.MirroredStrategy()\n",
    "    with mirrored_strategy.scope():\n",
    "        \n",
    "        \n",
    "        title_model, custom_layer = create_text_model(MAX_SEQUENCE_LENGTH, bert_ckpt_file, bert_config_file, NUM_CLASS, False, True, pathToBertModelTitle, False)\n",
    "        meta_model, model_meta_custom_layer = create_model_meta(NUM_CLASS, 2, True, pathToMetaModel, isTrainable=False)   \n",
    "\n",
    "        titleMetaModel, titleMetaModel_custom_layer = buildConcatModelTitleMeta(title_model, meta_model, 2, True, pathToTitleMetaModel, False)\n",
    "\n",
    "        preds =  titleMetaModel.predict(test_seq_dual_title_meta, use_multiprocessing=False, batch_size = GLOBAL_BATCH_SIZE, verbose=1) \n",
    "        test_max = np.argmax(preds, axis=1)\n",
    "\n",
    "        try:\n",
    "            df_eval_test.insert(loc=df_eval_test.shape[1], column='eval_dual_title_meta_pred_label_test', value=np.nan)\n",
    "        except ValueError:\n",
    "            print('Found columns, ignoring inserting')\n",
    "\n",
    "        for index, row in enumerate(df_eval_val.itertuples(), 1):\n",
    "            rowFine = convertRowToDictionary(row, df_eval_test.columns, True)\n",
    "            df_eval_test.at[row[0], 'eval_dual_title_meta_pred_label_test'] = int(test_max[index-1])\n",
    "        Q.put(df_eval_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3')\n",
      "bert shape (None, 128, 768)\n",
      "1842/1842 [==============================] - 155s 84ms/step\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3')\n",
      "bert shape (None, 128, 768)\n",
      "1842/1842 [==============================] - 155s 84ms/step\n"
     ]
    }
   ],
   "source": [
    "Q = Queue()\n",
    "process_eval = Process(target=evaluateTitleMetaVal, args=())\n",
    "process_eval.start()\n",
    "df_eval_val = Q.get()\n",
    "process_eval.join()\n",
    "\n",
    "Q = Queue()\n",
    "process_eval = Process(target=evaluateTitleMetaTest, args=())\n",
    "process_eval.start()\n",
    "df_eval_test = Q.get()\n",
    "process_eval.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluateTitleVisualVal():\n",
    "    mirrored_strategy = tf.distribute.MirroredStrategy()\n",
    "    with mirrored_strategy.scope():\n",
    "        \n",
    "        model_image, model_image_custom_layer = create_image_inceptionv3_model(NUM_CLASS=NUM_CLASS,isPreTrained=True,pathToInceptionV3ModelWeights=pathToImageModel, isTrainable=False)\n",
    "        model_bert, model_bert_custom_layer = create_text_model(max_seq_len=MAX_SEQUENCE_LENGTH, bert_ckpt_file=bert_ckpt_file, bert_config_file= bert_config_file,NUM_CLASS=NUM_CLASS, overwriteLayerAndEmbeddingSize=False, isPreTrained=True,  pathToBertModelWeights=pathToBertModelTitle, isTrainable=False) \n",
    "\n",
    "        titleVisual_model, titleVisual_custom_layer = buildConcatModelTitleImage(model_image, model_bert, 2, True, pathToTitleImageModel, False)\n",
    "\n",
    "        preds =  titleVisual_model.predict(val_seq_dual, use_multiprocessing=False, batch_size = GLOBAL_BATCH_SIZE, verbose=1) \n",
    "        test_max = np.argmax(preds, axis=1)\n",
    "\n",
    "        try:\n",
    "            df_eval_val.insert(loc=df_eval_val.shape[1], column='eval_dual_title_visual_pred_label_val', value=np.nan)\n",
    "        except ValueError:\n",
    "            print('Found columns, ignoring inserting')\n",
    "\n",
    "        for index, row in enumerate(df_eval_val.itertuples(), 1):\n",
    "            rowFine = convertRowToDictionary(row, df_eval_val.columns, True)\n",
    "            df_eval_val.at[row[0], 'eval_dual_title_visual_pred_label_val'] = int(test_max[index-1])\n",
    "        Q.put(df_eval_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluateTitleVisualTest():\n",
    "    mirrored_strategy = tf.distribute.MirroredStrategy()\n",
    "    with mirrored_strategy.scope():\n",
    "        inception_model, model_image_custom_layer = create_image_inceptionv3_model(NUM_CLASS=NUM_CLASS,isPreTrained=True,pathToInceptionV3ModelWeights=pathToImageModel, isTrainable=False)\n",
    "        title_model, custom_layer = create_text_model(MAX_SEQUENCE_LENGTH, bert_ckpt_file, bert_config_file, NUM_CLASS, False, True, pathToBertModelTitle, False)\n",
    "\n",
    "        titleVisual_model, titleVisual_custom_layer = buildConcatModelTitleImage(inception_model, title_model, 2, True, pathToTitleImageModel)\n",
    "\n",
    "        preds =  titleVisual_model.predict(test_seq_dual, use_multiprocessing=False, batch_size = GLOBAL_BATCH_SIZE, verbose=1) \n",
    "        test_max = np.argmax(preds, axis=1)\n",
    "\n",
    "        try:\n",
    "            df_eval_test.insert(loc=df_eval_test.shape[1], column='eval_dual_title_visual_pred_label_test', value=np.nan)\n",
    "        except ValueError:\n",
    "            print('Found columns, ignoring inserting')\n",
    "\n",
    "        for index, row in enumerate(df_eval_test.itertuples(), 1):\n",
    "            rowFine = convertRowToDictionary(row, df_eval_test.columns, True)\n",
    "            df_eval_test.at[row[0], 'eval_dual_title_visual_pred_label_test'] = int(test_max[index-1])\n",
    "        Q.put(df_eval_test)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3')\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "bert shape (None, 128, 768)\n",
      "1842/1842 [==============================] - 1383s 751ms/step\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3')\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "bert shape (None, 128, 768)\n",
      "1842/1842 [==============================] - 1387s 753ms/step\n"
     ]
    }
   ],
   "source": [
    "Q = Queue()\n",
    "process_eval = Process(target=evaluateTitleVisualVal, args=())\n",
    "process_eval.start()\n",
    "df_eval_val = Q.get()\n",
    "process_eval.join()\n",
    "\n",
    "Q = Queue()\n",
    "process_eval = Process(target=evaluateTitleVisualTest, args=())\n",
    "process_eval.start()\n",
    "df_eval_test = Q.get()\n",
    "process_eval.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluateTitleCommentsVisualVal():\n",
    "    mirrored_strategy = tf.distribute.MirroredStrategy()\n",
    "    with mirrored_strategy.scope():\n",
    "        inception_model, model_image_custom_layer = create_image_inceptionv3_model(NUM_CLASS=NUM_CLASS,isPreTrained=True,pathToInceptionV3ModelWeights=pathToImageModel, isTrainable=False)\n",
    "        title_model, custom_layer = create_text_model(MAX_SEQUENCE_LENGTH, bert_ckpt_file, bert_config_file, NUM_CLASS, False, True, pathToBertModelTitle, False)\n",
    "        comments_model, comments_modal_custom_layer = create_text_model(max_seq_len=MAX_SEQUENCE_LENGTH, bert_ckpt_file=bert_ckpt_file, bert_config_file= bert_config_file,NUM_CLASS=NUM_CLASS, overwriteLayerAndEmbeddingSize=False, isPreTrained=True,  pathToBertModelWeights=pathToBertModelComments, isTrainable=False) \n",
    "\n",
    "        # Handling same layer name error:\n",
    "        for i, layer in enumerate(title_model.layers):\n",
    "            layer._name = layer._name + '_title' # Consider the _ for the setter\n",
    "\n",
    "        titleVisual_model, custom_layer = buildConcatModelTitleCommentsVisual(title_model, comments_model, inception_model, NUM_CLASS, True, pathToTitleCommentsImage)\n",
    "\n",
    "        preds =  titleVisual_model.predict(val_seq_triple, use_multiprocessing=False, batch_size = GLOBAL_BATCH_SIZE, verbose=1) \n",
    "        test_max = np.argmax(preds, axis=1)\n",
    "\n",
    "        try:\n",
    "            df_eval_val.insert(loc=df_eval_val.shape[1], column='eval_triple_title_comments_visual_pred_label_val', value=np.nan)\n",
    "        except ValueError:\n",
    "            print('Found columns, ignoring inserting')\n",
    "\n",
    "        for index, row in enumerate(df_eval_val.itertuples(), 1):\n",
    "            rowFine = convertRowToDictionary(row, df_eval_val.columns, True)\n",
    "            df_eval_val.at[row[0], 'eval_triple_title_comments_visual_pred_label_val'] = int(test_max[index-1])\n",
    "        Q.put(df_eval_val) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluateTitleCommentsVisualTest():\n",
    "    mirrored_strategy = tf.distribute.MirroredStrategy()\n",
    "    with mirrored_strategy.scope():\n",
    "        inception_model, model_image_custom_layer = create_image_inceptionv3_model(NUM_CLASS=NUM_CLASS,isPreTrained=True,pathToInceptionV3ModelWeights=pathToImageModel, isTrainable=False)\n",
    "        title_model, custom_layer = create_text_model(MAX_SEQUENCE_LENGTH, bert_ckpt_file, bert_config_file, NUM_CLASS, False, True, pathToBertModelTitle, False)\n",
    "        comments_model, comments_modal_custom_layer = create_text_model(max_seq_len=MAX_SEQUENCE_LENGTH, bert_ckpt_file=bert_ckpt_file, bert_config_file= bert_config_file,NUM_CLASS=NUM_CLASS, overwriteLayerAndEmbeddingSize=False, isPreTrained=True,  pathToBertModelWeights=pathToBertModelComments, isTrainable=False) \n",
    "\n",
    "        # Handling same layer name error:\n",
    "        for i, layer in enumerate(title_model.layers):\n",
    "            layer._name = layer._name + '_title' # Consider the _ for the setter\n",
    "\n",
    "        titleVisual_model, custom_layer =  buildConcatModelTitleCommentsVisual(title_model, comments_model, inception_model, NUM_CLASS, True, pathToTitleCommentsImage)\n",
    "\n",
    "        preds =  titleVisual_model.predict(test_seq_triple, use_multiprocessing=False, batch_size = GLOBAL_BATCH_SIZE, verbose=1) \n",
    "        test_max = np.argmax(preds, axis=1)\n",
    "\n",
    "        try:\n",
    "            df_eval_test.insert(loc=df_eval_test.shape[1], column='eval_triple_title_comments_visual_pred_label_test', value=np.nan)\n",
    "        except ValueError:\n",
    "            print('Found columns, ignoring inserting')\n",
    "\n",
    "        for index, row in enumerate(df_eval_test.itertuples(), 1):\n",
    "            rowFine = convertRowToDictionary(row, df_eval_test.columns, True)\n",
    "            df_eval_test.at[row[0], 'eval_triple_title_comments_visual_pred_label_test'] = int(test_max[index-1])\n",
    "        Q.put(df_eval_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3')\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "bert shape (None, 128, 768)\n",
      "bert shape (None, 128, 768)\n",
      "1842/1842 [==============================] - 2498s 1s/step\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3')\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "bert shape (None, 128, 768)\n",
      "bert shape (None, 128, 768)\n",
      "1842/1842 [==============================] - 2502s 1s/step\n"
     ]
    }
   ],
   "source": [
    "Q = Queue()\n",
    "process_eval = Process(target=evaluateTitleCommentsVisualVal, args=())\n",
    "process_eval.start()\n",
    "df_eval_val = Q.get()\n",
    "process_eval.join()\n",
    "\n",
    "Q = Queue()\n",
    "process_eval = Process(target=evaluateTitleCommentsVisualTest, args=())\n",
    "process_eval.start()\n",
    "df_eval_test = Q.get()\n",
    "process_eval.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "def calcAccConcatModel(model_concat, test_seq, GLOBAL_BATCH_SIZE, name):\n",
    "    test = model_concat.predict(test_seq, use_multiprocessing=False, batch_size = GLOBAL_BATCH_SIZE, verbose=1)\n",
    "    test_max = np.argmax(test,axis=1)\n",
    "    unique_elements, counts_elements = np.unique(test_max, return_counts=True)\n",
    "    # print(\"Frequency of unique values of the said array:\")\n",
    "    # print(np.asarray((unique_elements, counts_elements)))\n",
    "    y_true = []\n",
    "    for index, element in enumerate(test_seq):\n",
    "        y_true.append(element[1])\n",
    "\n",
    "    y_true = [item for sublist in y_true for item in sublist]\n",
    "    y_true = [int(i) for i in y_true]\n",
    "\n",
    "    acc = accuracy_score(np.array(y_true), np.array(test_max))\n",
    "    print(f'{name} Accuracy is {acc}')\n",
    "    return f'{name} Accuracy is {acc}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluateTitleCommentsVisualMetaVal():\n",
    "    mirrored_strategy = tf.distribute.MirroredStrategy()\n",
    "    with mirrored_strategy.scope():\n",
    "        inception_model, model_image_custom_layer = create_image_inceptionv3_model(NUM_CLASS=NUM_CLASS,isPreTrained=True,pathToInceptionV3ModelWeights=pathToImageModel, isTrainable=False)\n",
    "        title_model, custom_layer = create_text_model(MAX_SEQUENCE_LENGTH, bert_ckpt_file, bert_config_file, NUM_CLASS, False, True, pathToBertModelTitle, False)\n",
    "        comments_model, comments_modal_custom_layer = create_text_model(max_seq_len=MAX_SEQUENCE_LENGTH, bert_ckpt_file=bert_ckpt_file, bert_config_file= bert_config_file,NUM_CLASS=NUM_CLASS, overwriteLayerAndEmbeddingSize=False, isPreTrained=True,  pathToBertModelWeights=pathToBertModelComments, isTrainable=False) \n",
    "        meta_model, model_meta_custom_layer = create_model_meta(NUM_CLASS, 2, True, pathToMetaModel, isTrainable=False)\n",
    "\n",
    "        # Handling same layer name error:\n",
    "        for i, layer in enumerate(title_model.layers):\n",
    "            layer._name = layer._name + '_title' # Consider the _ for the setter\n",
    "\n",
    "        all_four, custom_layer =  buildConcatModelTitleCommentsMetaVisual(title_model, comments_model, inception_model, meta_model, NUM_CLASS, True, pathToTitleCommentsImageMeta)\n",
    "\n",
    "        preds =  all_four.predict(val_seq, use_multiprocessing=False, batch_size = GLOBAL_BATCH_SIZE, verbose=1) \n",
    "        test_max = np.argmax(preds, axis=1)\n",
    "        calcAccConcatModel(all_four, val_seq, GLOBAL_BATCH_SIZE, 'Val')\n",
    "        try:\n",
    "            df_eval_val.insert(loc=df_eval_val.shape[1], column='eval_four_title_comments_visual_meta_pred_label_val', value=np.nan)\n",
    "        except ValueError:\n",
    "            print('Found columns, ignoring inserting')\n",
    "\n",
    "        for index, row in enumerate(df_eval_test.itertuples(), 1):\n",
    "            rowFine = convertRowToDictionary(row, df_eval_test.columns, True)\n",
    "            df_eval_val.at[row[0], 'eval_four_title_comments_visual_meta_pred_label_val'] = int(test_max[index-1])\n",
    "        Q.put(df_eval_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluateTitleCommentsVisualMetaTest():\n",
    "    mirrored_strategy = tf.distribute.MirroredStrategy()\n",
    "    with mirrored_strategy.scope():\n",
    "        inception_model, model_image_custom_layer = create_image_inceptionv3_model(NUM_CLASS=NUM_CLASS,isPreTrained=True,pathToInceptionV3ModelWeights=pathToImageModel, isTrainable=False)\n",
    "        title_model, custom_layer = create_text_model(MAX_SEQUENCE_LENGTH, bert_ckpt_file, bert_config_file, NUM_CLASS, False, True, pathToBertModelTitle, False)\n",
    "        comments_model, comments_modal_custom_layer = create_text_model(max_seq_len=MAX_SEQUENCE_LENGTH, bert_ckpt_file=bert_ckpt_file, bert_config_file= bert_config_file,NUM_CLASS=NUM_CLASS, overwriteLayerAndEmbeddingSize=False, isPreTrained=True,  pathToBertModelWeights=pathToBertModelComments, isTrainable=False) \n",
    "        meta_model, model_meta_custom_layer = create_model_meta(NUM_CLASS, 2, True, pathToMetaModel, isTrainable=False)\n",
    "\n",
    "        # Handling same layer name error:\n",
    "        for i, layer in enumerate(title_model.layers):\n",
    "            layer._name = layer._name + '_title' # Consider the _ for the setter\n",
    "\n",
    "        all_four, custom_layer =  buildConcatModelTitleCommentsMetaVisual(title_model, comments_model, inception_model, meta_model, NUM_CLASS, True, pathToTitleCommentsImageMeta)\n",
    "\n",
    "        preds =  all_four.predict(test_seq, use_multiprocessing=False, batch_size = GLOBAL_BATCH_SIZE, verbose=1) \n",
    "        test_max = np.argmax(preds, axis=1)\n",
    "        calcAccConcatModel(all_four, test_seq, GLOBAL_BATCH_SIZE, 'test')\n",
    "        try:\n",
    "            df_eval_test.insert(loc=df_eval_test.shape[1], column='eval_four_title_comments_visual_meta_pred_label_test', value=np.nan)\n",
    "        except ValueError:\n",
    "            print('Found columns, ignoring inserting')\n",
    "\n",
    "        for index, row in enumerate(df_eval_test.itertuples(), 1):\n",
    "            rowFine = convertRowToDictionary(row, df_eval_test.columns, True)\n",
    "            df_eval_test.at[row[0], 'eval_four_title_comments_visual_meta_pred_label_test'] = int(test_max[index-1])\n",
    "        Q.put(df_eval_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3')\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "bert shape (None, 128, 768)\n",
      "bert shape (None, 128, 768)\n",
      "1842/1842 [==============================] - 1406s 763ms/step\n",
      "1842/1842 [==============================] - 1405s 763ms/step\n",
      "Val Accuracy is 0.9521749457111836\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3')\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "bert shape (None, 128, 768)\n",
      "bert shape (None, 128, 768)\n",
      "1842/1842 [==============================] - 1407s 764ms/step\n",
      "1842/1842 [==============================] - 1407s 764ms/step\n",
      "test Accuracy is 0.9535321661237784\n"
     ]
    }
   ],
   "source": [
    "Q = Queue()\n",
    "process_eval = Process(target=evaluateTitleCommentsVisualMetaVal, args=())\n",
    "process_eval.start()\n",
    "df_eval_val = Q.get()\n",
    "process_eval.join()\n",
    "\n",
    "Q = Queue()\n",
    "process_eval = Process(target=evaluateTitleCommentsVisualMetaTest, args=())\n",
    "process_eval.start()\n",
    "df_eval_test = Q.get()\n",
    "process_eval.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "tableName   = \"validation\"\n",
    "sqlEngine = create_engine('mysql+pymysql://test:123password123@127.0.0.1/fid', pool_recycle=3600)\n",
    "dbConnection    = sqlEngine.connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test - all models fail: 279\n",
      "Val - all models fail: 157\n"
     ]
    }
   ],
   "source": [
    "# Test - all models fail\n",
    "a = len(dbConnection.execute(\"SELECT *  FROM `test` WHERE `2_way_label` = 0 AND `eval_title_pred_label_test` = 1 AND `eval_comments_pred_label_test` = 1 AND `eval_visual_pred_label_test` = 1 AND `eval_meta_pred_label_test` = 1 AND `eval_dual_title_meta_pred_label_test` = 1 AND `eval_dual_title_visual_pred_label_test` = 1 AND `eval_triple_title_comments_visual_pred_label_test` = 1 AND `eval_four_title_comments_visual_meta_pred_label_test` = 1\").fetchall())\n",
    "b = len(dbConnection.execute(\"SELECT *  FROM `test` WHERE `2_way_label` = 1 AND `eval_title_pred_label_test` = 0 AND `eval_comments_pred_label_test` = 0 AND `eval_visual_pred_label_test` = 0 AND `eval_meta_pred_label_test` = 0 AND `eval_dual_title_meta_pred_label_test` = 0 AND `eval_dual_title_visual_pred_label_test` = 0 AND `eval_triple_title_comments_visual_pred_label_test` = 0 AND `eval_four_title_comments_visual_meta_pred_label_test` = 0\").fetchall())\n",
    "print(f'Test - all models fail: {a + b}')\n",
    "\n",
    "# Val - all models fail\n",
    "a = len(dbConnection.execute(\"SELECT *  FROM `validation` WHERE `2_way_label` = 0 AND `eval_title_pred_label_val` = 1 AND `eval_comments_pred_label_val` = 1 AND `eval_visual_pred_label_val` = 1 AND `eval_meta_pred_label_val` = 1 AND `eval_dual_title_meta_pred_label_val` = 1 AND `eval_dual_title_visual_pred_label_val` = 1 AND `eval_triple_title_comments_visual_pred_label_val` = 1 AND `eval_four_title_comments_visual_meta_pred_label_val` = 1\").fetchall())\n",
    "b = len(dbConnection.execute(\"SELECT *  FROM `validation` WHERE `2_way_label` = 1 AND `eval_title_pred_label_val` = 0 AND `eval_comments_pred_label_val` = 0 AND `eval_visual_pred_label_val` = 0 AND `eval_meta_pred_label_val` = 0 AND `eval_dual_title_meta_pred_label_val` = 0 AND `eval_dual_title_visual_pred_label_val` = 0 AND `eval_triple_title_comments_visual_pred_label_val` = 0 AND `eval_four_title_comments_visual_meta_pred_label_val` = 0\").fetchall())\n",
    "print(f'Val - all models fail: {a + b}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meta correct, visual incorrect: 2194\n",
      "Meta correct, visual incorrect: 2189\n"
     ]
    }
   ],
   "source": [
    "# Test - all misclassified samples over all models fake, but all true\n",
    "\n",
    "a = len(dbConnection.execute(\"SELECT * FROM `test` WHERE `2_way_label` = 0 AND `eval_comments_pred_label_test` = 1 AND `eval_meta_pred_label_test` = 0\").fetchall())\n",
    "b = len(dbConnection.execute(\"SELECT * FROM `test` WHERE `2_way_label` = 1 AND `eval_comments_pred_label_test` = 0 AND `eval_meta_pred_label_test` = 1\").fetchall())\n",
    "print(f'Meta correct, visual incorrect: {a + b}')\n",
    "\n",
    "# Val - Meta correct, visual incorrect\n",
    "a = len(dbConnection.execute(\"SELECT * FROM `validation` WHERE `2_way_label` = 0 AND `eval_comments_pred_label_val` = 1 AND `eval_meta_pred_label_val` = 0\").fetchall())\n",
    "b = len(dbConnection.execute(\"SELECT * FROM `validation` WHERE `2_way_label` = 1 AND `eval_comments_pred_label_val` = 0 AND `eval_meta_pred_label_val` = 1\").fetchall())\n",
    "print(f'Meta correct, visual incorrect: {a + b}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "title correct, visual was false: 24882\n",
      "title correct, visual was false: 6419\n"
     ]
    }
   ],
   "source": [
    "# Test - title correct, visual was false\n",
    "\n",
    "a = len(dbConnection.execute(\"SELECT * FROM `test` WHERE `2_way_label` = 0 AND `eval_title_pred_label_test` = 0 AND `eval_visual_pred_label_test` = 1\").fetchall())\n",
    "b = len(dbConnection.execute(\"SELECT * FROM `test` WHERE `2_way_label` = 1 AND `eval_title_pred_label_test` = 1 AND `eval_visual_pred_label_test` = 0\").fetchall())\n",
    "print(f'title correct, visual was false: {a + b}')\n",
    "\n",
    "# Val - title correct, visual was false\n",
    "a = len(dbConnection.execute(\"SELECT * FROM `validation` WHERE `2_way_label` = 0 AND `eval_title_pred_label_val` = 0 AND `eval_meta_pred_label_val` = 1\").fetchall())\n",
    "b = len(dbConnection.execute(\"SELECT * FROM `validation` WHERE `2_way_label` = 1 AND `eval_title_pred_label_val` = 1 AND `eval_meta_pred_label_val` = 0\").fetchall())\n",
    "print(f'title correct, visual was false: {a + b}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test - visual correct, title was false: 3459\n",
      "Val - visual correct, title was false: 22834\n"
     ]
    }
   ],
   "source": [
    "# Test - visual correct, title was false\n",
    "\n",
    "a = len(dbConnection.execute(\"SELECT * FROM `test` WHERE `2_way_label` = 0 AND `eval_title_pred_label_test` = 1 AND `eval_visual_pred_label_test` = 0\").fetchall())\n",
    "b = len(dbConnection.execute(\"SELECT * FROM `test` WHERE `2_way_label` = 1 AND `eval_title_pred_label_test` = 0 AND `eval_visual_pred_label_test` = 1\").fetchall())\n",
    "print(f'Test - visual correct, title was false: {a + b}')\n",
    "\n",
    "# Val - visual correct, title was false\n",
    "a = len(dbConnection.execute(\"SELECT * FROM `validation` WHERE `2_way_label` = 0 AND `eval_title_pred_label_val` = 1 AND `eval_visual_pred_label_val` = 0\").fetchall())\n",
    "b = len(dbConnection.execute(\"SELECT * FROM `validation` WHERE `2_way_label` = 1 AND `eval_title_pred_label_val` = 0 AND `eval_visual_pred_label_val` = 1\").fetchall())\n",
    "print(f'Val - visual correct, title was false: {a + b}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " test - title correct, meta was false: 11374\n",
      "Val - title correct, meta was false: 6419\n"
     ]
    }
   ],
   "source": [
    "# Test - title correct, meta was false\n",
    "\n",
    "a = len(dbConnection.execute(\"SELECT * FROM `test` WHERE `2_way_label` = 0 AND `eval_title_pred_label_test` = 0 AND `eval_meta_pred_label_test` = 1\").fetchall())\n",
    "b = len(dbConnection.execute(\"SELECT * FROM `test` WHERE `2_way_label` = 1 AND `eval_title_pred_label_test` = 1 AND `eval_meta_pred_label_test` = 0\").fetchall())\n",
    "print(f' test - title correct, meta was false: {a + b}')\n",
    "\n",
    "# Val - title correct, meta was false\n",
    "a = len(dbConnection.execute(\"SELECT * FROM `validation` WHERE `2_way_label` = 0 AND `eval_title_pred_label_val` = 0 AND `eval_meta_pred_label_val` = 1\").fetchall())\n",
    "b = len(dbConnection.execute(\"SELECT * FROM `validation` WHERE `2_way_label` = 1 AND `eval_title_pred_label_val` = 1 AND `eval_meta_pred_label_val` = 0\").fetchall())\n",
    "print(f'Val - title correct, meta was false: {a + b}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test - title false, meta was true: 5041\n",
      "Val - title false, meta was true: 21691\n"
     ]
    }
   ],
   "source": [
    "# Test - title false, meta was true\n",
    "\n",
    "a = len(dbConnection.execute(\"SELECT * FROM `test` WHERE `2_way_label` = 0 AND `eval_title_pred_label_test` = 1 AND `eval_meta_pred_label_test` = 0\").fetchall())\n",
    "b = len(dbConnection.execute(\"SELECT * FROM `test` WHERE `2_way_label` = 1 AND `eval_title_pred_label_test` = 0 AND `eval_meta_pred_label_test` = 1\").fetchall())\n",
    "print(f'Test - title false, meta was true: {a + b}')\n",
    "\n",
    "# Val - title false, meta was true\n",
    "a = len(dbConnection.execute(\"SELECT * FROM `validation` WHERE `2_way_label` = 0 AND `eval_title_pred_label_val` = 1 AND `eval_meta_pred_label_val` = 0\").fetchall())\n",
    "b = len(dbConnection.execute(\"SELECT * FROM `validation` WHERE `2_way_label` = 1 AND `eval_title_pred_label_val` = 0 AND `eval_meta_pred_label_val` = 1\").fetchall())\n",
    "print(f'Val - title false, meta was true: {a + b}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meta correct, visual incorrect: 21612\n",
      "Meta correct, visual incorrect: 7966\n"
     ]
    }
   ],
   "source": [
    "# Test - Meta correct, visual incorrect\n",
    "a = len(dbConnection.execute(\"SELECT * FROM `test` WHERE `2_way_label` = 0 AND `eval_visual_pred_label_test` = 1 AND `eval_meta_pred_label_test` = 0\").fetchall())\n",
    "b = len(dbConnection.execute(\"SELECT * FROM `test` WHERE `2_way_label` = 1 AND `eval_visual_pred_label_test` = 0 AND `eval_meta_pred_label_test` = 1\").fetchall())\n",
    "print(f'Meta correct, visual incorrect: {a + b}')\n",
    "\n",
    "# Val - Meta correct, visual incorrect\n",
    "a = len(dbConnection.execute(\"SELECT * FROM `validation` WHERE `2_way_label` = 0 AND `eval_visual_pred_label_val` = 1 AND `eval_meta_pred_label_val` = 0\").fetchall())\n",
    "b = len(dbConnection.execute(\"SELECT * FROM `validation` WHERE `2_way_label` = 1 AND `eval_visual_pred_label_val` = 0 AND `eval_meta_pred_label_val` = 1\").fetchall())\n",
    "print(f'Meta correct, visual incorrect: {a + b}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " test - Meta incorrect, visual correct: 6522\n",
      "validation - Meta incorrect, visual correct: 9849\n"
     ]
    }
   ],
   "source": [
    "# Test - Meta incorrect, visual correct\n",
    "a = len(dbConnection.execute(\"SELECT * FROM `test` WHERE `2_way_label` = 0 AND `eval_visual_pred_label_test` = 0 AND `eval_meta_pred_label_test` = 1\").fetchall())\n",
    "b = len(dbConnection.execute(\"SELECT * FROM `test` WHERE `2_way_label` = 1 AND `eval_visual_pred_label_test` = 1 AND `eval_meta_pred_label_test` = 0\").fetchall())\n",
    "print(f' test - Meta incorrect, visual correct: {a + b}')\n",
    "\n",
    "# Val - Meta correct, visual incorrect\n",
    "a = len(dbConnection.execute(\"SELECT * FROM `validation` WHERE `2_way_label` = 0 AND `eval_visual_pred_label_val` = 0 AND `eval_meta_pred_label_val` = 1\").fetchall())\n",
    "b = len(dbConnection.execute(\"SELECT * FROM `validation` WHERE `2_way_label` = 1 AND `eval_visual_pred_label_val` = 1 AND `eval_meta_pred_label_val` = 0\").fetchall())\n",
    "print(f'validation - Meta incorrect, visual correct: {a + b}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "comments correct, visual incorrect: 24149\n",
      "val - comments correct, visual incorrect: 9158\n"
     ]
    }
   ],
   "source": [
    "# Test - comments correct, visual incorrect\n",
    "a = len(dbConnection.execute(\"SELECT * FROM `test` WHERE `2_way_label` = 0 AND `eval_visual_pred_label_test` = 1 AND `eval_comments_pred_label_test` = 0\").fetchall())\n",
    "b = len(dbConnection.execute(\"SELECT * FROM `test` WHERE `2_way_label` = 1 AND `eval_visual_pred_label_test` = 0 AND `eval_comments_pred_label_test` = 1\").fetchall())\n",
    "print(f'comments correct, visual incorrect: {a + b}')\n",
    "\n",
    "# Val - comments correct, visual incorrect\n",
    "a = len(dbConnection.execute(\"SELECT * FROM `validation` WHERE `2_way_label` = 0 AND `eval_visual_pred_label_val` = 1 AND `eval_comments_pred_label_val` = 0\").fetchall())\n",
    "b = len(dbConnection.execute(\"SELECT * FROM `validation` WHERE `2_way_label` = 1 AND `eval_visual_pred_label_val` = 0 AND `eval_comments_pred_label_val` = 1\").fetchall())\n",
    "print(f'val - comments correct, visual incorrect: {a + b}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "comments correct, visual incorrect: 3653\n",
      "val - comments correct, visual incorrect: 5824\n"
     ]
    }
   ],
   "source": [
    "# Test - comments incorrect, visual correct\n",
    "a = len(dbConnection.execute(\"SELECT * FROM `test` WHERE `2_way_label` = 0 AND `eval_visual_pred_label_test` = 0 AND `eval_comments_pred_label_test` = 1\").fetchall())\n",
    "b = len(dbConnection.execute(\"SELECT * FROM `test` WHERE `2_way_label` = 1 AND `eval_visual_pred_label_test` = 1 AND `eval_comments_pred_label_test` = 0\").fetchall())\n",
    "print(f'comments correct, visual incorrect: {a + b}')\n",
    "\n",
    "# Val - comments incorrect, visual correct\n",
    "a = len(dbConnection.execute(\"SELECT * FROM `validation` WHERE `2_way_label` = 0 AND `eval_visual_pred_label_val` = 0 AND `eval_comments_pred_label_val` = 1\").fetchall())\n",
    "b = len(dbConnection.execute(\"SELECT * FROM `validation` WHERE `2_way_label` = 1 AND `eval_visual_pred_label_val` = 1 AND `eval_comments_pred_label_val` = 0\").fetchall())\n",
    "print(f'val - comments correct, visual incorrect: {a + b}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " test title correct, comments incorrect: 6651\n",
      "val - title correct, comments incorrect: 3624\n"
     ]
    }
   ],
   "source": [
    "# Test - title correct, comments incorrect\n",
    "a = len(dbConnection.execute(\"SELECT * FROM `test` WHERE `2_way_label` = 0 AND `eval_title_pred_label_test` = 0 AND `eval_comments_pred_label_test` = 1\").fetchall())\n",
    "b = len(dbConnection.execute(\"SELECT * FROM `test` WHERE `2_way_label` = 1 AND `eval_title_pred_label_test` = 1 AND `eval_comments_pred_label_test` = 0\").fetchall())\n",
    "print(f' test title correct, comments incorrect: {a + b}')\n",
    "\n",
    "# Val - title correct, comments incorrect\n",
    "a = len(dbConnection.execute(\"SELECT * FROM `validation` WHERE `2_way_label` = 0 AND `eval_title_pred_label_val` = 0 AND `eval_comments_pred_label_val` = 1\").fetchall())\n",
    "b = len(dbConnection.execute(\"SELECT * FROM `validation` WHERE `2_way_label` = 1 AND `eval_title_pred_label_val` = 1 AND `eval_comments_pred_label_val` = 0\").fetchall())\n",
    "print(f'val - title correct, comments incorrect: {a + b}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test  comments correct, title incorrect: 7600\n",
      "val - comments correct, title incorrect: 7406\n"
     ]
    }
   ],
   "source": [
    "# Test - comments correct, meta incorrect\n",
    "a = len(dbConnection.execute(\"SELECT * FROM `test` WHERE `2_way_label` = 0 AND `eval_meta_pred_label_test` = 1 AND `eval_comments_pred_label_test` = 0\").fetchall())\n",
    "b = len(dbConnection.execute(\"SELECT * FROM `test` WHERE `2_way_label` = 1 AND `eval_meta_pred_label_test` = 0 AND `eval_comments_pred_label_test` = 1\").fetchall())\n",
    "print(f'test  comments correct, title incorrect: {a + b}')\n",
    "\n",
    "# Val - comments correct, meta incorrect\n",
    "a = len(dbConnection.execute(\"SELECT * FROM `validation` WHERE `2_way_label` = 0 AND `eval_meta_pred_label_val` = 1 AND `eval_comments_pred_label_val` = 0\").fetchall())\n",
    "b = len(dbConnection.execute(\"SELECT * FROM `validation` WHERE `2_way_label` = 1 AND `eval_meta_pred_label_val` = 0 AND `eval_comments_pred_label_val` = 1\").fetchall())\n",
    "print(f'val - comments correct, title incorrect: {a + b}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test - Meta correct, comments incorrect: 2194\n",
      "val - Meta correct, comments incorrect: 5674\n"
     ]
    }
   ],
   "source": [
    "# Test - comments incorrect, meta correct\n",
    "a = len(dbConnection.execute(\"SELECT * FROM `test` WHERE `2_way_label` = 0 AND `eval_meta_pred_label_test` = 0 AND `eval_comments_pred_label_test` = 1\").fetchall())\n",
    "b = len(dbConnection.execute(\"SELECT * FROM `test` WHERE `2_way_label` = 1 AND `eval_meta_pred_label_test` = 1 AND `eval_comments_pred_label_test` = 0\").fetchall())\n",
    "print(f'test - Meta correct, comments incorrect: {a + b}')\n",
    "\n",
    "# Val - comments correct, meta incorrect\n",
    "a = len(dbConnection.execute(\"SELECT * FROM `validation` WHERE `2_way_label` = 0 AND `eval_meta_pred_label_val` = 0 AND `eval_comments_pred_label_val` = 1\").fetchall())\n",
    "b = len(dbConnection.execute(\"SELECT * FROM `validation` WHERE `2_way_label` = 0 AND `eval_meta_pred_label_val` = 1 AND `eval_comments_pred_label_val` = 0\").fetchall())\n",
    "print(f'val - Meta correct, comments incorrect: {a + b}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test  comments correct, title incorrect: 5724\n",
      "val - comments correct, title incorrect: 24113\n"
     ]
    }
   ],
   "source": [
    "# Test - comments correct, title incorrect\n",
    "a = len(dbConnection.execute(\"SELECT * FROM `test` WHERE `2_way_label` = 0 AND `eval_title_pred_label_test` = 1 AND `eval_comments_pred_label_test` = 0\").fetchall())\n",
    "b = len(dbConnection.execute(\"SELECT * FROM `test` WHERE `2_way_label` = 1 AND `eval_title_pred_label_test` = 0 AND `eval_comments_pred_label_test` = 1\").fetchall())\n",
    "print(f'test  comments correct, title incorrect: {a + b}')\n",
    "\n",
    "# Val - comments correct, title incorrect\n",
    "a = len(dbConnection.execute(\"SELECT * FROM `validation` WHERE `2_way_label` = 0 AND `eval_title_pred_label_val` = 1 AND `eval_comments_pred_label_val` = 0\").fetchall())\n",
    "b = len(dbConnection.execute(\"SELECT * FROM `validation` WHERE `2_way_label` = 1 AND `eval_title_pred_label_val` = 0 AND `eval_comments_pred_label_val` = 1\").fetchall())\n",
    "print(f'val - comments correct, title incorrect: {a + b}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dual models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Single true, dual (title visual) false: 388\n",
      "Val Single true, dual (title visual) false: 619\n"
     ]
    }
   ],
   "source": [
    "# Test - Single true, dual (title visual) false\n",
    "a = len(dbConnection.execute(\"SELECT * FROM `test` WHERE `2_way_label` = 0 AND `eval_title_pred_label_test` = 0 AND `eval_comments_pred_label_test` = 0 AND `eval_visual_pred_label_test` = 0 AND `eval_meta_pred_label_test` = 0 AND `eval_dual_title_visual_pred_label_test` = 1\").fetchall())\n",
    "b = len(dbConnection.execute(\"SELECT * FROM `test` WHERE `2_way_label` = 1 AND `eval_title_pred_label_test` = 1 AND `eval_comments_pred_label_test` = 1 AND `eval_visual_pred_label_test` = 1 AND `eval_meta_pred_label_test` = 1 AND `eval_dual_title_visual_pred_label_test` = 0\").fetchall())\n",
    "print(f'Test Single true, dual (title visual) false: {a + b}')\n",
    "\n",
    "# Val - Single true, dual (title visual) false\n",
    "a = len(dbConnection.execute(\"SELECT * FROM `validation` WHERE `2_way_label` = 0 AND `eval_title_pred_label_val` = 0 AND `eval_comments_pred_label_val` = 0 AND `eval_visual_pred_label_val` = 0 AND `eval_meta_pred_label_val` = 0 AND `eval_dual_title_visual_pred_label_val` = 1\").fetchall())\n",
    "b = len(dbConnection.execute(\"SELECT * FROM `validation` WHERE `2_way_label` = 1 AND `eval_title_pred_label_val` = 1 AND `eval_comments_pred_label_val` = 1 AND `eval_visual_pred_label_val` = 1 AND `eval_meta_pred_label_val` = 1 AND `eval_dual_title_visual_pred_label_val` = 0\").fetchall())\n",
    "print(f'Val Single true, dual (title visual) false: {a + b}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Single true, dual (title visual) false: 89\n",
      "Val Single true, dual (title visual) false: 1551\n"
     ]
    }
   ],
   "source": [
    "# Test - Single true, dual (title meta) false\n",
    "a = len(dbConnection.execute(\"SELECT * FROM `test` WHERE `2_way_label` = 0 AND `eval_title_pred_label_test` = 0 AND `eval_comments_pred_label_test` = 0 AND `eval_visual_pred_label_test` = 0 AND `eval_meta_pred_label_test` = 0 AND `eval_dual_title_meta_pred_label_test` = 1\").fetchall())\n",
    "b = len(dbConnection.execute(\"SELECT * FROM `test` WHERE `2_way_label` = 1 AND `eval_title_pred_label_test` = 1 AND `eval_comments_pred_label_test` = 1 AND `eval_visual_pred_label_test` = 1 AND `eval_meta_pred_label_test` = 1 AND `eval_dual_title_meta_pred_label_test` = 0\").fetchall())\n",
    "print(f'Test Single true, dual (title visual) false: {a + b}')\n",
    "\n",
    "# Val - Single true, dual (title meta) false\n",
    "a = len(dbConnection.execute(\"SELECT * FROM `validation` WHERE `2_way_label` = 0 AND `eval_title_pred_label_val` = 0 AND `eval_comments_pred_label_val` = 0 AND `eval_visual_pred_label_val` = 0 AND `eval_meta_pred_label_val` = 0 AND `eval_dual_title_meta_pred_label_val` = 1\").fetchall())\n",
    "b = len(dbConnection.execute(\"SELECT * FROM `validation` WHERE `2_way_label` = 1 AND `eval_title_pred_label_val` = 1 AND `eval_comments_pred_label_val` = 1 AND `eval_visual_pred_label_val` = 1 AND `eval_meta_pred_label_val` = 1 AND `eval_dual_title_meta_pred_label_val` = 0\").fetchall())\n",
    "print(f'Val Single true, dual (title visual) false: {a + b}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tripple Models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Three better than all ones: 75\n",
      " val Three better than all ones: 115\n"
     ]
    }
   ],
   "source": [
    "# Test - Three worser than all ones,\n",
    "a = len(dbConnection.execute(\"SELECT * FROM `test` WHERE `2_way_label` = 1 AND `eval_title_pred_label_test` = 1 AND `eval_comments_pred_label_test` = 1 AND `eval_visual_pred_label_test` = 1 AND `eval_meta_pred_label_test` = 1 AND `eval_triple_title_comments_visual_pred_label_test` = 0\").fetchall())\n",
    "b = len(dbConnection.execute(\"SELECT * FROM `test` WHERE `2_way_label` = 0 AND `eval_title_pred_label_test` = 0 AND `eval_comments_pred_label_test` = 0 AND `eval_visual_pred_label_test` = 0 AND `eval_meta_pred_label_test` = 0 AND `eval_triple_title_comments_visual_pred_label_test` = 1\").fetchall())\n",
    "print(f'Test Three worser than all ones: {a + b}')\n",
    "\n",
    "# Val - Three worser worser all ones\n",
    "a = len(dbConnection.execute(\"SELECT * FROM `validation` WHERE `2_way_label` = 1 AND `eval_title_pred_label_val` = 1 AND `eval_comments_pred_label_val` = 1 AND `eval_visual_pred_label_val` = 1 AND `eval_meta_pred_label_val` = 1 AND `eval_triple_title_comments_visual_pred_label_val` = 0\").fetchall())\n",
    "b = len(dbConnection.execute(\"SELECT * FROM `validation` WHERE `2_way_label` = 0 AND `eval_title_pred_label_val` = 0 AND `eval_comments_pred_label_val` = 0 AND `eval_visual_pred_label_val` = 0 AND `eval_meta_pred_label_val` = 0 AND `eval_triple_title_comments_visual_pred_label_val` = 1\").fetchall())\n",
    "print(f' val Three better than all ones: {a + b}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Three better than all ones: 90\n",
      " val Three better than all ones: 370\n"
     ]
    }
   ],
   "source": [
    "# Test - Three better than all ones,\n",
    "a = len(dbConnection.execute(\"SELECT * FROM `test` WHERE `2_way_label` = 0 AND `eval_title_pred_label_test` = 1 AND `eval_comments_pred_label_test` = 1 AND `eval_visual_pred_label_test` = 1 AND `eval_meta_pred_label_test` = 1 AND `eval_triple_title_comments_visual_pred_label_test` = 0\").fetchall())\n",
    "b = len(dbConnection.execute(\"SELECT * FROM `test` WHERE `2_way_label` = 1 AND `eval_title_pred_label_test` = 0 AND `eval_comments_pred_label_test` = 0 AND `eval_visual_pred_label_test` = 0 AND `eval_meta_pred_label_test` = 0 AND `eval_triple_title_comments_visual_pred_label_test` = 1\").fetchall())\n",
    "print(f'Test Three better than all ones: {a + b}')\n",
    "\n",
    "# Val - Three better than all ones\n",
    "a = len(dbConnection.execute(\"SELECT * FROM `validation` WHERE `2_way_label` = 0 AND `eval_title_pred_label_val` = 1 AND `eval_comments_pred_label_val` = 1 AND `eval_visual_pred_label_val` = 1 AND `eval_meta_pred_label_val` = 1 AND `eval_triple_title_comments_visual_pred_label_val` = 0\").fetchall())\n",
    "b = len(dbConnection.execute(\"SELECT * FROM `validation` WHERE `2_way_label` = 1 AND `eval_title_pred_label_val` = 0 AND `eval_comments_pred_label_val` = 0 AND `eval_visual_pred_label_val` = 0 AND `eval_meta_pred_label_val` = 0 AND `eval_triple_title_comments_visual_pred_label_val` = 1\").fetchall())\n",
    "print(f' val Three better than all ones: {a + b}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## quadro models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Test - Single true, quadro false: 52\n",
      "Single true, quadro false: 96\n"
     ]
    }
   ],
   "source": [
    "# Test - Single true, quadro false\n",
    "a = len(dbConnection.execute(\"SELECT * FROM `test` WHERE `2_way_label` = 0 AND `eval_title_pred_label_test` = 0 AND `eval_comments_pred_label_test` = 0 AND `eval_visual_pred_label_test` = 0 AND `eval_meta_pred_label_test` = 0 AND `eval_four_title_comments_visual_meta_pred_label_test` = 1\").fetchall())\n",
    "b = len(dbConnection.execute(\"SELECT * FROM `test` WHERE `2_way_label` = 1 AND `eval_title_pred_label_test` = 1 AND `eval_comments_pred_label_test` = 1 AND `eval_visual_pred_label_test` = 1 AND `eval_meta_pred_label_test` = 1 AND `eval_four_title_comments_visual_meta_pred_label_test` = 0\").fetchall())\n",
    "print(f' Test - Single true, quadro false: {a + b}')\n",
    "\n",
    "# Val  - Single true, quadro false\n",
    "a = len(dbConnection.execute(\"SELECT * FROM `validation` WHERE `2_way_label` = 0 AND `eval_title_pred_label_val` = 0 AND `eval_comments_pred_label_val` = 0 AND `eval_visual_pred_label_val` = 0 AND `eval_meta_pred_label_val` = 0 AND `eval_four_title_comments_visual_meta_pred_label_val` = 1\").fetchall())\n",
    "b = len(dbConnection.execute(\"SELECT * FROM `validation` WHERE `2_way_label` = 1 AND `eval_title_pred_label_val` = 1 AND `eval_comments_pred_label_val` = 1 AND `eval_visual_pred_label_val` = 1 AND `eval_meta_pred_label_val` = 1 AND `eval_four_title_comments_visual_meta_pred_label_val` = 0\").fetchall())\n",
    "print(f'Single true, quadro false: {a + b}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single false, quadro true: 52\n",
      "Single false, quadro true) false: 379\n"
     ]
    }
   ],
   "source": [
    "# Test - Single false, quadro true\n",
    "a = len(dbConnection.execute(\"SELECT * FROM `test` WHERE `2_way_label` = 0 AND `eval_title_pred_label_test` = 0 AND `eval_comments_pred_label_test` = 0 AND `eval_visual_pred_label_test` = 0 AND `eval_meta_pred_label_test` = 0 AND `eval_four_title_comments_visual_meta_pred_label_test` = 1\").fetchall())\n",
    "b = len(dbConnection.execute(\"SELECT * FROM `test` WHERE `2_way_label` = 1 AND `eval_title_pred_label_test` = 1 AND `eval_comments_pred_label_test` = 1 AND `eval_visual_pred_label_test` = 1 AND `eval_meta_pred_label_test` = 1 AND `eval_four_title_comments_visual_meta_pred_label_test` = 0\").fetchall())\n",
    "print(f'Single false, quadro true: {a + b}')\n",
    "\n",
    "# Val  - Single false, quadro true\n",
    "a = len(dbConnection.execute(\"SELECT * FROM `validation` WHERE `2_way_label` = 1 AND `eval_title_pred_label_val` = 0 AND `eval_comments_pred_label_val` = 0 AND `eval_visual_pred_label_val` = 0 AND `eval_meta_pred_label_val` = 0 AND `eval_four_title_comments_visual_meta_pred_label_val` = 1\").fetchall())\n",
    "b = len(dbConnection.execute(\"SELECT * FROM `validation` WHERE `2_way_label` = 0 AND `eval_title_pred_label_val` = 1 AND `eval_comments_pred_label_val` = 1 AND `eval_visual_pred_label_val` = 1 AND `eval_meta_pred_label_val` = 1 AND `eval_four_title_comments_visual_meta_pred_label_val` = 0\").fetchall())\n",
    "print(f'Single false, quadro true) false: {a + b}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Quadro misclassified: 2739\n",
      "Validation Quadro misclassified: 2819\n"
     ]
    }
   ],
   "source": [
    "# Test - Quadro Samples misclassified\n",
    "a = len(dbConnection.execute(\"SELECT * FROM `test` WHERE `2_way_label` = 0 AND `eval_four_title_comments_visual_meta_pred_label_test` = 1\").fetchall())\n",
    "b = len(dbConnection.execute(\"SELECT * FROM `test` WHERE `2_way_label` = 1 AND `eval_four_title_comments_visual_meta_pred_label_test` = 0\").fetchall())\n",
    "print(f'Test Quadro misclassified: {a + b}')\n",
    "\n",
    "# Val  - Quadro Samples misclassified\n",
    "a = len(dbConnection.execute(\"SELECT * FROM `validation` WHERE `2_way_label` = 0 AND `eval_four_title_comments_visual_meta_pred_label_val` = 1\").fetchall())\n",
    "b = len(dbConnection.execute(\"SELECT * FROM `validation` WHERE `2_way_label` = 1 AND `eval_four_title_comments_visual_meta_pred_label_val` = 0\").fetchall())\n",
    "print(f'Validation Quadro misclassified: {a + b}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Quadro correct: 56205\n",
      "Validation Quadro correct: 56125\n"
     ]
    }
   ],
   "source": [
    "# Test - Quadro Samples correct\n",
    "a = len(dbConnection.execute(\"SELECT * FROM `test` WHERE `2_way_label` = 1 AND `eval_four_title_comments_visual_meta_pred_label_test` = 1\").fetchall())\n",
    "b = len(dbConnection.execute(\"SELECT * FROM `test` WHERE `2_way_label` = 0 AND `eval_four_title_comments_visual_meta_pred_label_test` = 0\").fetchall())\n",
    "print(f'Test Quadro correct: {a + b}')\n",
    "\n",
    "# Val  - Quadro Samples correct\n",
    "a = len(dbConnection.execute(\"SELECT * FROM `validation` WHERE `2_way_label` = 1 AND `eval_four_title_comments_visual_meta_pred_label_val` = 1\").fetchall())\n",
    "b = len(dbConnection.execute(\"SELECT * FROM `validation` WHERE `2_way_label` = 0 AND `eval_four_title_comments_visual_meta_pred_label_val` = 0\").fetchall())\n",
    "print(f'Validation Quadro correct: {a + b}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eval_val.to_sql(tableName, dbConnection, if_exists='append')\n",
    "tableName   = \"test\"\n",
    "df_eval_test.to_sql(tableName, dbConnection, if_exists='append')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eval_val.to_csv(pathToEvalValCSV, index=False, sep='|')\n",
    "df_eval_test.to_csv(pathToEvalTestCSV, index=False, sep='|')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
